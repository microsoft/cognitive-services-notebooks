{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics with the Python SDK\n",
    "\n",
    "This walkthrough shows you how to analyze four different aspects of text documents using the Text Analytics SDK for Python: language detection, sentiment analysis, key phrase extraction, and named entity recognition.\n",
    "\n",
    "You can run this example as a Jupyter notebook on [MyBinder](https://mybinder.org) by clicking on the **Launch Binder** badge below.\n",
    "\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/Microsoft/cognitive-services-notebooks/master?filepath=TextAnalytics.ipynb)\n",
    "\n",
    "Refer to the Text Analytics service's [REST API documentation](https://westus.dev.cognitive.microsoft.com/docs/services/TextAnalytics-v2-1/operations/56f30ceeeda5650db055a3c7) for a reference to the four types of analysis that can be performed by the Text Analytics service.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This Quickstart requires Python 3.0 or later and the Text Analytics SDK module for Python. You can install the required module with the following shell command.\n",
    "\n",
    "```bash\n",
    "python -m pip install azure-cognitiveservices-language-textanalytics\n",
    "```\n",
    "\n",
    "This also installs any other modules that are required by the Text Analytics SDK, if you don't already have them.\n",
    "\n",
    "If you are using your own Jupyter installation to run the code in a notebook, make sure the IPython kernel is up-to-date.\n",
    "\n",
    "```bash\n",
    "python -m pip install --upgrade IPython\n",
    "```\n",
    " \n",
    "> **TIP** While you could call the [HTTP endpoints](https://westus.dev.cognitive.microsoft.com/docs/services/TextAnalytics-v2-1/operations/56f30ceeeda5650db055a3c7) directly from Python, the SDK makes it much easier to use the service without having to worry about HTTP requests or JSON.\n",
    ">\n",
    "> A couple of useful links:\n",
    "> - [SDK PyPi page](https://pypi.org/project/azure-cognitiveservices-language-textanalytics/)\n",
    "> - [SDK code](https://github.com/Azure/azure-sdk-for-python)\n",
    "\n",
    "You must have a [Cognitive Services API subscription](https://docs.microsoft.com/azure/cognitive-services/cognitive-services-apis-create-account) with access to the Text Analytics API. If you don't have a subscription, you can [create an account](https://azure.microsoft.com/try/cognitive-services/?api=bing-web-search-api) for free. Before continuing, you will need the Text Analytics subscription key provided after activating your account.\n",
    "\n",
    "Make a note of the [endpoint and subscription key](../How-tos/text-analytics-how-to-access-key.md) associated with your subscription.\n",
    "\n",
    "The code in this Quickstart is presented in short snippets. You can run it on Binder (or your own Jupyter notebook) by placing the cursor into a code block and pressing Control-Enter. You can also run the code by pasting each snippet at the Python command line.\n",
    "\n",
    "> **NOTE** Some of the text in the example data is in Spanish and Chinese. Some characters may not appear correctly in a command line session, depending on your platform, locale, and shell. If possible, set your shell to use the UTF-8 text encoding. If collecting the snippets into a file, save the file as UTF-8 and include `# -*- coding: utf-8 -*` at the top of the file.\n",
    "\n",
    "Run the following code before running the snippets in other sections. Replace the `None` value of `subscription_key` with a valid Text Analytics or Cognitive Services subscription key (as a string) and verify that the region in the `endpoint` URL corresponds to the one you used when setting up the service. (If you are using a free trial key, it's in the `westcentralus` region, so you don't need to change the URL.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Text Analytics SDK client v2.1 initialized"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient, models\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "try:\n",
    "    from IPython.display import HTML\n",
    "    assert get_ipython().__class__.__name__ == \"ZMQInteractiveShell\"\n",
    "except Exception:\n",
    "    HTML = print    # simply print HTML if we're not in a Jupyter notebook\n",
    "\n",
    "subscription_key = None\n",
    "assert subscription_key, \"Provide a valid Text Analytics subscription key\"\n",
    "\n",
    "endpoint = \"https://westcentralus.api.cognitive.microsoft.com\"\n",
    "\n",
    "client = TextAnalyticsClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "HTML(\"Text Analytics SDK client {} initialized\".format(client.api_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code:\n",
    "\n",
    "* Detects whether it is being run in a Jupyter notebook. If not, the `HTML` class (which is used to insert an HTML result into a Jupyter notebook) is set to a reference to the `print` command.\n",
    "* Sets the subscription key and endpoint, then initializes a Text Analytics client using those variables.\n",
    "\n",
    "## Detect language\n",
    "\n",
    "The Text Analytics client's [`detect_language` method](https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-language-textanalytics/azure.cognitiveservices.language.textanalytics.text_analytics_client.textanalyticsclient?view=azure-python#detect-language-show-stats-none--documents-none--custom-headers-none--raw-false----operation-config-) detects the language of submitted text documents. A document is plain text in a supported language; it need not be in a file.\n",
    "\n",
    "To reduce the number of calls involved in processing large numbers of documents, multiple documents may be submitted in a single `detect_language` call. The input to the method is a list of individual documents, each of which is represented by a `LanguageInput` instance.\n",
    "\n",
    "As a `LanguageInput` object, each document has `id` and `text` attributes. The `text` attribute stores the text to be analyzed. The `id` attribute is a string that associates each result with its original document, and must be unique within the document set for each `detect_language` call. A sample list with three documents is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3 results"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_docs = [ models.LanguageInput(id=\"1\", text=\"This is a document written in English.\"),\n",
    "                  models.LanguageInput(id=\"2\", text=\"Este es un document escrito en Español.\"),\n",
    "                  models.LanguageInput(id=\"3\", text='这是一个用中文写的文件')\n",
    "                ]\n",
    "\n",
    "language_results = client.detect_language(documents=language_docs)\n",
    "HTML(\"{} results\".format(len(language_results.documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the `detect_language()` call returns, `language_results.documents` is a list in the same order as `language_docs`. For each original document, a `LanguageBatchResultItem` is provided, containing information about the language or languages detected in the document. \n",
    "\n",
    "Each result item contains a `detected_languages` attribute that holds a list of `DetectedLanguage` objects, each corresponding to a language found in the document. The `name` attribute of this object contains the human-readable name of the language, such as `English`, and the `score` attribute contains how certain the Text Analytics service is of the result on a scale from 0.0 to 1.0.\n",
    "\n",
    "The following Python code generates an HTML table showing the original text and the detected language or languages, along with each language's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th><p>ID</th><th><p>Text</th><th><p>Languages (scores)</th></tr><tr><td><p>1</td><td><p>This is a document written in English.</td><td><p>English en (1.0)</td></tr>\n",
       "<tr><td><p>2</td><td><p>Este es un document escrito en Español.</td><td><p>Spanish es (1.0)</td></tr>\n",
       "<tr><td><p>3</td><td><p>这是一个用中文写的文件</td><td><p>Chinese Simplified zh_chs (1.0)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = []\n",
    "header = \"<tr><th><p>{}</th><th><p>{}</th><th><p>{}</th></tr>\".format(\"ID\", \"Text\", \"Languages (scores)\")\n",
    "\n",
    "for doc, res in zip(language_docs, language_results.documents):\n",
    "    langs = \", \".join(\"{} {} ({})\".format(lang.name.replace(\"_\", \" \"), \n",
    "        lang.iso6391_name, lang.score) for lang in res.detected_languages)\n",
    "    row = \"<tr><td><p>{doc.id}</td><td><p>{doc.text}</td><td><p>{langs}</td></tr>\".format(doc=doc, langs=langs)\n",
    "    table.append(row)\n",
    "\n",
    "HTML(\"<table>{0}{1}</table>\".format(header, \"\\n\".join(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze sentiment\n",
    "\n",
    "The [`sentiment` method](https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-language-textanalytics/azure.cognitiveservices.language.textanalytics.text_analytics_client.textanalyticsclient?view=azure-python#sentiment-show-stats-none--documents-none--custom-headers-none--raw-false----operation-config-) detects the sentiment of text documents, on a scale of 0.0 (unfavorable) to 1.0 (favorable). Values around 0.5 represent neutral sentiment.\n",
    "\n",
    "In practice, a sentiment analysis call works much like a language detection call. Multiple pieces of text (\"documents\") can be submitted in a single call, and each document must have a unique ID within the set of documents in a given `sentiment` call. \n",
    "\n",
    "You must also specify the language of each document using ISO 639-1 language codes, such as `en` for English. The `MultiLanguageInput` class holds the required information about each document. \n",
    "\n",
    "The following example scores four documents, two in English and *dos* in Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4 results"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_docs = [ \n",
    "    models.MultiLanguageInput(id=\"1\", language=\"en\", \n",
    "        text=\"I had a wonderful experience! The rooms were wonderful and the staff was helpful.\"),\n",
    "    models.MultiLanguageInput(id=\"2\", language=\"en\", \n",
    "        text=\"I had a terrible time at the hotel. The staff was rude and the food was awful.\"),\n",
    "    models.MultiLanguageInput(id=\"3\", language=\"es\", \n",
    "        text=\"Los caminos que llevan hasta Monte Rainier son espectaculares y hermosos.\"),\n",
    "    models.MultiLanguageInput(id=\"4\", language=\"es\", \n",
    "        text=\"La carretera estaba atascada. Había mucho tráfico el día de ayer.\"),\n",
    "]\n",
    "\n",
    "sentiment_results = client.sentiment(documents=sentiment_docs)\n",
    "HTML(\"{} results\".format(len(sentiment_results.documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the `sentiment` call, `sentiment_results.documents` is a list of `SentimentBatchResultItem` instances, each corresponding to a submitted document. The `SentimentBatchResultItem` includes a `score` attribute, which is the detected sentiment value. The Python code below displays the sentiment results as an HTML table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th><p>ID</th><th><p>Text</th><th><p>Score</th></tr><tr><td><p>1</td><td><p>I had a wonderful experience! The rooms were wonderful and the staff was helpful.</td><td><p>0.971</td></tr>\n",
       "<tr><td><p>2</td><td><p>I had a terrible time at the hotel. The staff was rude and the food was awful.</td><td><p>0.002</td></tr>\n",
       "<tr><td><p>3</td><td><p>Los caminos que llevan hasta Monte Rainier son espectaculares y hermosos.</td><td><p>0.746</td></tr>\n",
       "<tr><td><p>4</td><td><p>La carretera estaba atascada. Había mucho tráfico el día de ayer.</td><td><p>0.334</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = []\n",
    "header = \"<tr><th><p>{}</th><th><p>{}</th><th><p>{}</th></tr>\".format(\"ID\", \"Text\", \"Score\")\n",
    "\n",
    "for doc, res in zip(sentiment_docs, sentiment_results.documents):\n",
    "    row = \"<tr><td><p>{doc.id}</td><td><p>{doc.text}</td><td><p>{score:0.3f}</td></tr>\".format(\n",
    "        doc=doc, score=res.score)\n",
    "    table.append(row)\n",
    "\n",
    "HTML(\"<table>{0}{1}</table>\".format(header, \"\\n\".join(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract key phrases\n",
    "\n",
    "The [`key_phrases` method](https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-language-textanalytics/azure.cognitiveservices.language.textanalytics.text_analytics_client.textanalyticsclient?view=azure-python#key-phrases-show-stats-none--documents-none--custom-headers-none--raw-false----operation-config-) extracts key phrases from a text document.\n",
    "\n",
    "A key phrase extraction call works much like a sentiment analysis call. Multiple \"document can be submitted in a single call, and each document must have a unique ID within the set of documents in a given `key_phrases` call. \n",
    "\n",
    "You must specify the language of each document using ISO 639-1 language codes, such as `en` for English. The `MultiLanguageInput` class holds the required information about each document. \n",
    "\n",
    "We'll use the same documents we used for sentiment analysis in this example: four documents, half in English and half in Spanish. Here's the code to pass them to the `key_phrases` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4 results"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_phrases_docs = [ \n",
    "    models.MultiLanguageInput(id=\"1\", language=\"en\", \n",
    "        text=\"I had a wonderful experience! The rooms were wonderful and the staff was helpful.\"),\n",
    "    models.MultiLanguageInput(id=\"2\", language=\"en\", \n",
    "        text=\"I had a terrible time at the hotel. The staff was rude and the food was awful.\"),\n",
    "    models.MultiLanguageInput(id=\"3\", language=\"es\", \n",
    "        text=\"Los caminos que llevan hasta Monte Rainier son espectaculares y hermosos.\"),\n",
    "    models.MultiLanguageInput(id=\"4\", language=\"es\", \n",
    "        text=\"La carretera estaba atascada. Había mucho tráfico el día de ayer.\"),\n",
    "]\n",
    "\n",
    "key_phrases_results = client.key_phrases(documents=key_phrases_docs)\n",
    "HTML(\"{} results\".format(len(key_phrases_results.documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much as we've seen with other methods, after the `key_phrases` call, `key_phrases_results.documents` is a list of `KeyPhraseBatchResultItem` instances, each corresponding to a submitted document. The `KeyPhraseBatchResultItem` has a `key_phrases` attribute, which is the detected sentiment value. The Python code below displays the results as an HTML table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th><p>ID</th><th><p>Text</th><th><p>Key phrases</th></tr><tr><td><p>1</td><td><p>I had a wonderful experience! The rooms were wonderful and the staff was helpful.</td><td><p>wonderful experience, staff, rooms</td></tr>\n",
       "<tr><td><p>2</td><td><p>I had a terrible time at the hotel. The staff was rude and the food was awful.</td><td><p>food, terrible time, hotel, staff</td></tr>\n",
       "<tr><td><p>3</td><td><p>Los caminos que llevan hasta Monte Rainier son espectaculares y hermosos.</td><td><p>Monte Rainier, caminos</td></tr>\n",
       "<tr><td><p>4</td><td><p>La carretera estaba atascada. Había mucho tráfico el día de ayer.</td><td><p>carretera, tráfico, día</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = []\n",
    "header = \"<tr><th><p>{}</th><th><p>{}</th><th><p>{}</th></tr>\".format(\"ID\", \"Text\", \"Key phrases\")\n",
    "\n",
    "for doc, res in zip(key_phrases_docs, key_phrases_results.documents):\n",
    "    phrases = \", \".join(res.key_phrases)\n",
    "    row = \"<tr><td><p>{doc.id}</td><td><p>{doc.text}</td><td><p>{phrases}</td></tr>\".format(doc=doc, phrases=phrases)\n",
    "    table.append(row)\n",
    "\n",
    "HTML(\"<table>{0}{1}</table>\".format(header, \"\\n\".join(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the [`entities` method](https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-language-textanalytics/azure.cognitiveservices.language.textanalytics.text_analytics_client.textanalyticsclient?view=azure-python#entities-show-stats-none--documents-none--custom-headers-none--raw-false----operation-config-) identifies entities (businesses, people, places, and other proper nouns) in a text document.\n",
    "\n",
    "The overall process is familiar. Multiple documents can be submitted in a single call, and each document must have a unique ID within the set of documents in a given `entities` call. \n",
    "\n",
    "You must specify the language of each document using ISO 639-1 language codes, such as `en` for English. The `MultiLanguageInput` class stores the required information about each document. \n",
    "\n",
    "As before, here's our document set (this time just in English) and our Python method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "2 results"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_docs = [ \n",
    "    models.MultiLanguageInput(id=\"1\", language=\"en\", text=\"I really enjoy the new XBOX One S. \"\n",
    "        \"It's got a clean look, it's got 4K/HDR resolution, and it is affordable.\"),\n",
    "    models.MultiLanguageInput(id=\"2\", language=\"en\", \n",
    "        text=\"The Seattle Seahawks won the Super Bowl in 2014.\")\n",
    "]\n",
    "\n",
    "entity_results = client.entities(documents=entity_docs)\n",
    "HTML(\"{} results\".format(len(entity_results.documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, `entity_results.documents` is a list of `EntitiesBatchResultItem` instances corresponding to the submitted documents. The `entities` attribute of each object is a list of `EntityRecord` objects, each describing an entity recognized in the original document. \n",
    "\n",
    "There are several attributes of interest on an `EntityRecord` object, including its Bing ID, which can be used to retrieve more information about the entity using [Bing Entity Search](https://azure.microsoft.com/services/cognitive-services/bing-entity-search-api/). In this example, we'll use `name` (the entity's formal name),  `type` (its type), and `matches` (information about the parts of the document that were matched as each entity).\n",
    "\n",
    "The following Python code produces an HTML table containing each recognized entity's formal name, its type, and its matches' text and location within the original document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th><p>ID</th><th><p>Text</th><th><p>Entities found</th></tr><tr><td><p>1</td><td><p>I really enjoy the new XBOX One S. It's got a clean look, it's got 4K/HDR resolution, and it is affordable.</td><td><p><I>Xbox One (Other):</i><br>\"XBOX One S.\" in chars 23-33<p><I>4K resolution (Quantity):</i><br>\"4K\" in chars 67-68<p><I>4K/HDR (Organization):</i><br>\"4K/HDR\" in chars 67-72<p><I>High-dynamic-range imaging (Other):</i><br>\"HDR\" in chars 70-72</td></tr>\n",
       "<tr><td><p>2</td><td><p>The Seattle Seahawks won the Super Bowl in 2014.</td><td><p><I>2005 Seattle Seahawks season (Other):</i><br>\"The Seattle Seahawks\" in chars 0-19<p><I>Super Bowl (Other):</i><br>\"the Super Bowl\" in chars 25-38<p><I>2014 (DateTime):</i><br>\"2014\" in chars 43-46</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = []\n",
    "header = \"<tr><th><p>{}</th><th><p>{}</th><th><p>{}</th></tr>\".format(\"ID\", \"Text\", \"Entities found\")\n",
    "\n",
    "for doc, res in zip(entity_docs, entity_results.documents):\n",
    "    entities = \"\".join(\"<p><I>{} ({}):</i>{}\".format(e.name, e.type, \n",
    "        \"\".join('<br>\"{}\" in chars {}-{}'.format(m.text, m.offset, m.offset + m.length - 1)\n",
    "        for m in e.matches)) for e in res.entities)\n",
    "    row = \"<tr><td><p>{doc.id}</td><td><p>{doc.text}</td><td>{entities}</td></tr>\".format(doc=doc, entities=entities)\n",
    "    table.append(row)\n",
    "\n",
    "HTML(\"<table>{0}{1}</table>\".format(header, \"\\n\".join(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "> [Text Analytics With Power BI](../tutorials/tutorial-power-bi-key-phrases.md)\n",
    "\n",
    "## See also \n",
    "\n",
    " [Text Analytics overview](../overview.md)  \n",
    " [Frequently asked questions (FAQ)](../text-analytics-resource-faq.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "ms_docs_meta": {
   "author": "luiscabrer",
   "description": "Get information and code samples to help you quickly get started using the Text Analytics API in Microsoft Cognitive Services on Azure.",
   "documentationcenter": "''",
   "ms.author": "luisca",
   "ms.date": "04/15/2019",
   "ms.service": "cognitive-services",
   "ms.technology": "text-analytics",
   "ms.topic": "article",
   "services": "cognitive-services",
   "title": "Python Quickstart for Azure Cognitive Services, Text Analytics API | Microsoft Docs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
