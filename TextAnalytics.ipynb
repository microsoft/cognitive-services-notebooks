{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart for Text Analytics API with Python \n",
    "<a name=\"HOLTop\"></a>\n",
    "\n",
    "This walkthrough shows you how to [detect language](#Detect), [analyze sentiment](#SentimentAnalysis), and [extract key phrases](#KeyPhraseExtraction) using the [Text Analytics APIs](//go.microsoft.com/fwlink/?LinkID=759711) with Python.\n",
    "\n",
    "You can run this example as a Jupyter notebook on [MyBinder](https://mybinder.org) by clicking on the launch Binder badge: \n",
    "\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/Microsoft/cognitive-services-notebooks/master?filepath=TextAnalytics.ipynb)\n",
    "\n",
    "Refer to the [API definitions](//go.microsoft.com/fwlink/?LinkID=759346) for technical documentation for the APIs.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You must have a [Cognitive Services API account](https://docs.microsoft.com/azure/cognitive-services/cognitive-services-apis-create-account) with **Text Analytics API**. You can use the **free tier for 5,000 transactions/month** to complete this walkthrough.\n",
    "\n",
    "You must also have the [endpoint and access key](../How-tos/text-analytics-how-to-access-key.md) that was generated for you during sign-up. \n",
    "\n",
    "To continue with this walkthrough, replace `subscription_key` with a valid subscription key that you obtained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subscription_key = None\n",
    "assert subscription_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, verify that the region in `text_analytics_base_url` corresponds to the one you used when setting up the service. If you are using a free trial key, you do not need to change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_analytics_base_url = \"https://westcentralus.api.cognitive.microsoft.com/text/analytics/v2.0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Detect\"></a>\n",
    "\n",
    "## Detect languages\n",
    "\n",
    "The Language Detection API detects the language of a text document, using the [Detect Language method](https://westus.dev.cognitive.microsoft.com/docs/services/TextAnalytics.V2.0/operations/56f30ceeeda5650db055a3c7). The service endpoint of the language detection API for your region is available via the following URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westcentralus.api.cognitive.microsoft.com/text/analytics/v2.0/languages\n"
     ]
    }
   ],
   "source": [
    "language_api_url = text_analytics_base_url + \"languages\"\n",
    "print(language_api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The payload to the API consists of a list of `documents`, each of which in turn contains an `id` and a `text` attribute. The `text` attribute stores the text to be analyzed. \n",
    "\n",
    "Replace the `documents` dictionary with any other text for language detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = { 'documents': [\n",
    "    { 'id': '1', 'text': 'This is a document written in English.' },\n",
    "    { 'id': '2', 'text': 'Este es un document escrito en Español.' },\n",
    "    { 'id': '3', 'text': '这是一个用中文写的文件' }\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few lines of code call out to the language detection API using the `requests` library in Python to determine the language in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [{'detectedLanguages': [{'iso6391Name': 'en',\n",
      "                                       'name': 'English',\n",
      "                                       'score': 1.0}],\n",
      "                'id': '1'},\n",
      "               {'detectedLanguages': [{'iso6391Name': 'es',\n",
      "                                       'name': 'Spanish',\n",
      "                                       'score': 1.0}],\n",
      "                'id': '2'},\n",
      "               {'detectedLanguages': [{'iso6391Name': 'zh_chs',\n",
      "                                       'name': 'Chinese_Simplified',\n",
      "                                       'score': 1.0}],\n",
      "                'id': '3'}],\n",
      " 'errors': []}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "headers   = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "response  = requests.post(language_api_url, headers=headers, json=documents)\n",
    "languages = response.json()\n",
    "pprint(languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code render the JSON data as an HTML table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Text</th><th>Detected languages(scores)</th></tr><tr><td>This is a document written in English.</td><td>English(1.0)</td>\n",
       "<tr><td>Este es un document escrito en Español.</td><td>Spanish(1.0)</td>\n",
       "<tr><td>这是一个用中文写的文件</td><td>Chinese_Simplified(1.0)</td></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "table = []\n",
    "for document in languages[\"documents\"]:\n",
    "    text  = next(filter(lambda d: d[\"id\"] == document[\"id\"], documents[\"documents\"]))[\"text\"]\n",
    "    langs = \", \".join([\"{0}({1})\".format(lang[\"name\"], lang[\"score\"]) for lang in document[\"detectedLanguages\"]])\n",
    "    table.append(\"<tr><td>{0}</td><td>{1}</td>\".format(text, langs))\n",
    "HTML(\"<table><tr><th>Text</th><th>Detected languages(scores)</th></tr>{0}</table>\".format(\"\\n\".join(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"SentimentAnalysis\"></a>\n",
    "\n",
    "## Analyze sentiment\n",
    "\n",
    "The Sentiment Analysis API detexts the sentiment of a set of text records, using the [Sentiment method](https://westus.dev.cognitive.microsoft.com/docs/services/TextAnalytics.V2.0/operations/56f30ceeeda5650db055a3c9). The following example scores two documents, one in English and another in Spanish.\n",
    "\n",
    "The service endpoint for sentiment analysis is available for your region via the following URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westcentralus.api.cognitive.microsoft.com/text/analytics/v2.0/sentiment\n"
     ]
    }
   ],
   "source": [
    "sentiment_api_url = text_analytics_base_url + \"sentiment\"\n",
    "print(sentiment_api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the language detection example, the service is provided with a dictionary with a `documents` key that consists of a list of documents. Each document is a tuple consisting of the `id`, the `text` to be analyzed and the `language` of the text. You can use the language detection API from the previous section to populate this field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = {'documents' : [\n",
    "  {'id': '1', 'language': 'en', 'text': 'I had a wonderful experience! The rooms were wonderful and the staff was helpful.'},\n",
    "  {'id': '2', 'language': 'en', 'text': 'I had a terrible time at the hotel. The staff was rude and the food was awful.'},  \n",
    "  {'id': '3', 'language': 'es', 'text': 'Los caminos que llevan hasta Monte Rainier son espectaculares y hermosos.'},  \n",
    "  {'id': '4', 'language': 'es', 'text': 'La carretera estaba atascada. Había mucho tráfico el día de ayer.'}\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment API can now be used to analyze the documents for their sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [{'id': '1', 'score': 0.9552919864654541},\n",
      "               {'id': '2', 'score': 0.002100616693496704},\n",
      "               {'id': '3', 'score': 0.7456425428390503},\n",
      "               {'id': '4', 'score': 0.334433376789093}],\n",
      " 'errors': []}\n"
     ]
    }
   ],
   "source": [
    "headers   = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "response  = requests.post(sentiment_api_url, headers=headers, json=documents)\n",
    "sentiments = response.json()\n",
    "pprint(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment score for a document is between $0$ and $1$, with a higher score indicating a more positive sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"KeyPhraseExtraction\"></a>\n",
    "\n",
    "## Extract key phrases\n",
    "\n",
    "The Key Phrase Extraction API extracts key-phrases from a text document, using the [Key Phrases method](https://westus.dev.cognitive.microsoft.com/docs/services/TextAnalytics.V2.0/operations/56f30ceeeda5650db055a3c6). This section of the walkthrough extracts key phrases for both English and Spanish documents.\n",
    "\n",
    "The service endpoint for the key-phrase extraction service is accessed via the following URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westcentralus.api.cognitive.microsoft.com/text/analytics/v2.0/keyPhrases\n"
     ]
    }
   ],
   "source": [
    "key_phrase_api_url = text_analytics_base_url + \"keyPhrases\"\n",
    "print(key_phrase_api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of documents is the same as what was used for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [{'id': '1',\n",
      "                'language': 'en',\n",
      "                'text': 'I had a wonderful experience! The rooms were '\n",
      "                        'wonderful and the staff was helpful.'},\n",
      "               {'id': '2',\n",
      "                'language': 'en',\n",
      "                'text': 'I had a terrible time at the hotel. The staff was '\n",
      "                        'rude and the food was awful.'},\n",
      "               {'id': '3',\n",
      "                'language': 'es',\n",
      "                'text': 'Los caminos que llevan hasta Monte Rainier son '\n",
      "                        'espectaculares y hermosos.'},\n",
      "               {'id': '4',\n",
      "                'language': 'es',\n",
      "                'text': 'La carretera estaba atascada. Había mucho tráfico el '\n",
      "                        'día de ayer.'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [{'id': '1',\n",
      "                'keyPhrases': ['wonderful experience', 'staff', 'rooms']},\n",
      "               {'id': '2',\n",
      "                'keyPhrases': ['food', 'terrible time', 'hotel', 'staff']},\n",
      "               {'id': '3', 'keyPhrases': ['Monte Rainier', 'caminos']},\n",
      "               {'id': '4', 'keyPhrases': ['carretera', 'tráfico', 'día']}],\n",
      " 'errors': []}\n"
     ]
    }
   ],
   "source": [
    "headers   = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "response  = requests.post(key_phrase_api_url, headers=headers, json=documents)\n",
    "key_phrases = response.json()\n",
    "pprint(key_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON object can once again be rendered as an HTML table using the following lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Text</th><th>Key phrases</th></tr><tr><td>I had a wonderful experience! The rooms were wonderful and the staff was helpful.</td><td>wonderful experience,staff,rooms</td>\n",
       "<tr><td>I had a terrible time at the hotel. The staff was rude and the food was awful.</td><td>food,terrible time,hotel,staff</td>\n",
       "<tr><td>Los caminos que llevan hasta Monte Rainier son espectaculares y hermosos.</td><td>Monte Rainier,caminos</td>\n",
       "<tr><td>La carretera estaba atascada. Había mucho tráfico el día de ayer.</td><td>carretera,tráfico,día</td></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "table = []\n",
    "for document in key_phrases[\"documents\"]:\n",
    "    text    = next(filter(lambda d: d[\"id\"] == document[\"id\"], documents[\"documents\"]))[\"text\"]    \n",
    "    phrases = \",\".join(document[\"keyPhrases\"])\n",
    "    table.append(\"<tr><td>{0}</td><td>{1}</td>\".format(text, phrases))\n",
    "HTML(\"<table><tr><th>Text</th><th>Key phrases</th></tr>{0}</table>\".format(\"\\n\".join(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "> [!div class=\"nextstepaction\"]\n",
    "> [Text Analytics With Power BI](../tutorials/tutorial-power-bi-key-phrases.md)\n",
    "\n",
    "## See also \n",
    "\n",
    " [Text Analytics overview](../overview.md)  \n",
    " [Frequently asked questions (FAQ)](../text-analytics-resource-faq.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "ms_docs_meta": {
   "author": "luiscabrer",
   "description": "Get information and code samples to help you quickly get started using the Text Analytics API in Microsoft Cognitive Services on Azure.",
   "documentationcenter": "''",
   "ms.author": "luisca",
   "ms.date": "08/24/2017",
   "ms.service": "cognitive-services",
   "ms.technology": "text-analytics",
   "ms.topic": "article",
   "services": "cognitive-services",
   "title": "Python Quickstart for Azure Cognitive Services, Text Analytics API | Microsoft Docs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
